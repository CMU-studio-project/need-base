{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rARnVYhmXo91"
      },
      "source": [
        "# Hugging Face Dataset Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_-WYZgnJSlY",
        "outputId": "38991a9f-8787-4754-bb8d-32807f7257bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.9.0-py3-none-any.whl (462 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.8/462.8 KB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n",
            "Collecting huggingface-hub<1.0.0,>=0.2.0\n",
            "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2022.11.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.25.1)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 KB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: xxhash, urllib3, multiprocess, responses, huggingface-hub, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed datasets-2.9.0 huggingface-hub-0.12.0 multiprocess-0.70.14 responses-0.18.0 urllib3-1.26.14 xxhash-3.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyArR4g9aMzH"
      },
      "source": [
        "# RoBERTa Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJnCLI6EBu1O",
        "outputId": "e35e7baa-5cca-4076-df2c-2c977b8fd88c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.12.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "Successfully installed tokenizers-0.13.2 transformers-4.26.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from scipy) (1.21.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Lp-WeGckJ0en"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from scipy.special import softmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IONIiqwxmdt",
        "outputId": "43771704-68bd-4f43-e934-9e1fbf13d938"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.8/dist-packages (2.9.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.25.1)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2022.11.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets) (0.70.14)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fq-BOsCieaGv"
      },
      "outputs": [],
      "source": [
        "def acc(y_true, y_pred):\n",
        "    count=0\n",
        "    total=len(y_true)\n",
        "    for i in range(total):\n",
        "        if y_true[i]==y_pred[i]:\n",
        "          count+=1\n",
        "    return count/total\n",
        "\n",
        "def f1_value(y_true,y_pred):\n",
        "    tp=tn=fp=fn=0\n",
        "    total=len(y_true)\n",
        "    for i in range(total):\n",
        "        if y_true[i]==1 and y_pred[i]==1:\n",
        "          tp+=1\n",
        "        elif y_true[i]==1 and y_pred[i]==0:\n",
        "          fn+=1\n",
        "        elif y_true[i]==0 and y_pred[i]==1:\n",
        "          fp+=1\n",
        "        elif y_true[i]==0 and y_pred[i]==0:\n",
        "          tn+=1\n",
        "    precision=tp/(tp+fp)\n",
        "    recall=tp/(tp+fn)\n",
        "    f1=2*precision*recall/(precision+recall)\n",
        "    return f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWFL3Gd-gM14"
      },
      "outputs": [],
      "source": [
        "def preprocessor(sentence):\n",
        "    words=[]\n",
        "    for word in sentence.split(' '):\n",
        "        if word.startswith('@') and len(word) > 1:\n",
        "            word = '@user'\n",
        "        \n",
        "        elif word.startswith('http'):\n",
        "            word = \"http\"\n",
        "        words.append(word)\n",
        "\n",
        "    new_sentence = \" \".join(words)\n",
        "    return new_sentence\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kE0LYU7RCHth"
      },
      "outputs": [],
      "source": [
        "# load model and tokenizer\n",
        "roberta = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(roberta)\n",
        "tokenizer = AutoTokenizer.from_pretrained(roberta)\n",
        "\n",
        "labels = ['Negative', 'Neutral', 'Positive']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_9int44ooqq"
      },
      "outputs": [],
      "source": [
        "questions=[\"You're cheering for Quidditch. How do you feel when the team you support wins but it turned out that they used fouls?\",\n",
        "            \"You are trying to save Hermione, who was taken by a troll. How do you feel at this time?\", \n",
        "           \"Your team won the Quidditch game, but you found that it was thanks to Harry being attacked by Dementors during the match. In this case, what will you say to whom?\",\n",
        "           \"You got on the train to Hogwarts. the only empty seat is next to Luna Lovegood, who is reading with a magazine upside down, wearing a cane in her left ear, and a necklace made of the lid \",\n",
        "           \"You received a turnip earring and a spider ring from Luna Lovegood. How would you feel at this time?\"]\n",
        "\n",
        "answers=[[\"Still, I don't think it's a good idea to win by foul play\",\n",
        "          \"I would get disappointed at them\",\n",
        "          \"I would feel not so good because I hope my team win fairly\",\n",
        "          \"I would be dissapointed in our team.\",\n",
        "          \"I might be disappointed with them.\",\n",
        "          \"I feel satisfied.\"],\n",
        "         [\"I'll gladly help her\",\n",
        "          \"I'd get get angry and frustrated\",\n",
        "          \"I would feel scared, but not that much. I would concentrate on how to save her from troll.\",\n",
        "          \"I will be scared a bit but I know that I have to save her.\",\n",
        "          \"I would feel a bit scared but I would focus on rescuing Hermione.\",\n",
        "          \"I would be irritated.\"],\n",
        "         [\"I'll tell the dementors it's wrong\",\n",
        "          \"I'll say to Harry that i appreciate him for the sacrifice\",\n",
        "          \"I would first say to any of the professors that Harry is under attack. If the game is over, I will wait for the decision whether to have re-match or not\",\n",
        "          \"I would say to my team that it's unfair.\",\n",
        "          \"I would say to Harry if he's okay and feel sorry to him and his team.\",\n",
        "          \"I would tell Harry that he couldn’t help it.\"],\n",
        "         [\"It's a bit awkward, but I'll have to sit down\",\n",
        "          \"She is kind of strange but having interesting traits\",\n",
        "          \"Oh, it's interesting. This is a very interesting costume.\",\n",
        "          \"I would think her as a strange student and feel a bit uncomfortable.\",\n",
        "          \"I would think that she is awkward and I don't want to be close to her.\",\n",
        "          \"I would feel irritated.\"],\n",
        "         [\"I guess I'll answer why she is giving me this.\",\n",
        "          \"It's interesting\",\n",
        "          \"Why did she give them to me? Should I wear them?\",\n",
        "          \"I would feel thank you but will not wear them..\",\n",
        "          \"I would feel thankful to her but also think odd at the same time. \",\n",
        "          \"I would feel confused.\"]]\n",
        "\n",
        "label_list=[[2,2,2,1,1,4],\n",
        "            [5,1,3,3,4,3],\n",
        "            [2,5,3,2,2,2],\n",
        "            [2,4,4,2,1,2],\n",
        "            [2,4,1,3,2,1]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rm0x-xTFCLUx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "\n",
        "\n",
        "label=[\"\",'Strong Negative', 'Weak Negative', 'Natural', 'Weak Positive', 'Strong Positive']\n",
        "n_total=len(questions)*len(answers[0])\n",
        "avg_time=0\n",
        "cnt=0\n",
        "for i in range(len(questions)):\n",
        "    for j in range(len(answers[i])):\n",
        "        question=questions[i]\n",
        "        sentence=answers[i][j]\n",
        "        start_time=time.time()\n",
        "        preprocessed=preprocessor(sentence)\n",
        "        encoded=tokenizer(preprocessed, return_tensors='pt')\n",
        "        output=model(**encoded)\n",
        "        scores=output[0][0].detach().numpy()\n",
        "        scores = softmax(scores)\n",
        "        diff=time.time()-start_time\n",
        "        avg_time+=diff\n",
        "        # print(\"scores: \", scores)\n",
        "        # print(\"argmax: \", np.argmax(scores))\n",
        "        # print(\"type: \",type(scores))\n",
        "        inferenced_class=labels[np.argmax(scores)]\n",
        "        labeled_class=label[label_list[i][j]]\n",
        "        print(\"question        : \", question)\n",
        "        print(\"answer          : \", sentence)\n",
        "        print(\"labeled         : \", labeled_class)\n",
        "        print(\"Inference time  : \", diff)\n",
        "        print(\"Inference Result: \", inferenced_class)\n",
        "        for k in range(len(scores)):\n",
        "            l = labels[k]\n",
        "            s = scores[k]\n",
        "            print(l,s)\n",
        "        if labeled_class=='Weak Negative' or labeled_class=='Strong Negative':\n",
        "            labeled_class='Negative'\n",
        "        elif labeled_class=='Weak Positive' or labeled_class=='Strong Positive':\n",
        "            labeled_class='Positive'\n",
        "        elif labeled_class=='Natural':\n",
        "            labeled_class='Neutral'\n",
        "        if labeled_class==inferenced_class:\n",
        "            print(\"\\ninferenced class is same with labeled class !!\")\n",
        "            cnt+=1\n",
        "        else:\n",
        "            print(\"\\ninferenced class is different with labeled class !!\")\n",
        "        print(\"\\n\\n ======================================= \\n\\n\")\n",
        "\n",
        "avg_time/=n_total\n",
        "acc=cnt/n_total\n",
        "print(\"average time: \",avg_time)\n",
        "print(\"average acc : \",acc)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
